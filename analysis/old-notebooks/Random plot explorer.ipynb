{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "%matplotlib inline\n",
    "import mpld3\n",
    "mpld3.enable_notebook()\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary of datasets on LLNL. Checks if they exist and how many files\n",
    "### Note, the integer index of this dictionary matches the row number in the google-spreadsheet log\n",
    "##### https://docs.google.com/spreadsheets/d/14KmVPS824ExjVpss9H6fMSNVhopGtHVclZNsw5kKLr8/edit?usp=sharing\n",
    "##### Save this sheet to your own drive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for datasets in top directory: /p/lustre1/angelico/hv-test-chamber/\n",
      "2: 1-29-21/pmt-trig-filling-1800\t\tTrue, with 3019 files\n",
      "3: 1-29-21/pmt-trig-filling-1920\t\tTrue, with 81718 files\n",
      "4: 1-30-21/anode-crosstrig-1300\t\tTrue, with 161 files\n",
      "5: 1-30-21/anode-crosstrig-1320\t\tFalse\n",
      "6: 1-30-21/ignition-1500\t\tTrue, with 3795 files\n",
      "7: 1-30-21/ignition-10k-1520\t\tTrue, with 10849 files\n",
      "8: 1-31-21/glitch-1520\t\tTrue, with 10398 files\n",
      "9: 2-1-21/anode-100\t\tTrue, with 15628 files\n",
      "10: 2-1-21/anode-1340\t\tTrue, with 208 files\n",
      "11: 2-1-21/glitch-1530\t\tTrue, with 5333 files\n",
      "12: 2-1-21/glitch-2230\t\tTrue, with 8129 files\n",
      "13: 2-2-21/anode-1030\t\tTrue, with 22247 files\n",
      "14: 2-2-21/corona-1300\t\tTrue, with 2817 files\n",
      "15: 2-2-21/glitch-1320\t\tTrue, with 14598 files\n",
      "16: 2-2-21/glitch-1430\t\tFalse\n",
      "17: 2-2-21/anode-1720\t\tTrue, with 21034 files\n",
      "18: 2-3-21/glitch-1040\t\tFalse\n",
      "19: 2-3-21/anode-1050\t\tTrue, with 59444 files\n",
      "20: 2-3-21/glitch-1810\t\tFalse\n",
      "21: 2-3-21/anode-1820\t\tTrue, with 156841 files\n"
     ]
    }
   ],
   "source": [
    "datasets = {0: \"./8-15-21/filter-test/30kV/\", \\\n",
    "           1: \"./8-15-21/5kV-pmts/\", \\\n",
    "           2: \"./8-15-21/5kV-glitch/\"}\n",
    "\n",
    "for key, filepath in datasets.items():\n",
    "    if(os.path.isdir(filepath) == False):\n",
    "        print(\"WARNING: \" + filepath + \" is not a directory\")\n",
    "        continue\n",
    "    else:\n",
    "        files = [name for name in os.listdir(filepath) if os.path.isfile(os.path.join(filepath, name))]\n",
    "        files = [_ for _ in files if _[-3:] == \"csv\"]\n",
    "        num_files = len(files)\n",
    "        if(num_files == 0):\n",
    "            print(\"WARNING: no csv files in \" + filepath)\n",
    "        else:\n",
    "            print(\"Found : \" + str(num_files) + \" csv files in \" + filepath + \", dataset \" + str(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions for parsing file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_timestamp_from_filename(infile):\n",
    "    #infile looks like /path/to/data/file/pmt06.15.23.43.132.csv (day, hour, minute, second, milli)\n",
    "    fn = infile.split('/')[-1]\n",
    "    t = fn.split(\".\")\n",
    "    t[0] = t[0][-2:] #ignore the filetag prefix\n",
    "    timestamp = datetime.strptime('.'.join(t[:-1]), \"%d.%H.%M.%S.%f\")\n",
    "    return timestamp\n",
    "\n",
    "\n",
    "#looks at the input directory (a dataset) and\n",
    "#finds all .csv files, separating them by file prefix\n",
    "def get_separated_file_lists(indir, file_prefixes, nevents=None):\n",
    "    #full list of .csv files\n",
    "    file_list = []\n",
    "    if(nevents is not None):\n",
    "        for i, f in enumerate(os.listdir(indir)):\n",
    "            if(i > nevents):\n",
    "                break\n",
    "            if(os.path.isfile(os.path.join(indir, f)) \\\n",
    "                 and f.endswith('.csv')):\n",
    "                file_list.append(f)\n",
    "    else:\n",
    "        file_list = [f for f in os.listdir(indir) if os.path.isfile(os.path.join(indir, f)) \\\n",
    "                 and f.endswith('.csv')]\n",
    "\n",
    "    separate_file_lists = {}\n",
    "    for pref in file_prefixes:\n",
    "        #selects filenames by prefix. so separate_file_lists['pmt'] = ['pmt14.53.24.449', 'pmt10.34....', ...]\n",
    "        separate_file_lists[pref] = list(filter(lambda x: x[:len(pref)] == pref, file_list))  \n",
    "    \n",
    "    return separate_file_lists\n",
    "\n",
    "#converts the dictionary of separated file lists into\n",
    "#a dictionary of separated timestamps (units milliseconds)\n",
    "def get_separated_timestamps(separated_file_lists):\n",
    "    separated_timestamps = {}\n",
    "    for pref in separated_file_lists:\n",
    "        separated_timestamps[pref] = [parse_timestamp_from_filename(f) for f\\\n",
    "                                      in separated_file_lists[pref]]\n",
    "        \n",
    "        #if there are none from one of the prefixes, return empty lists\n",
    "        if(len(separated_timestamps[pref]) == 0):\n",
    "            separated_file_lists[pref] = []\n",
    "            continue\n",
    "            \n",
    "        #sort both the timestamps lists and the filelists\n",
    "        #simultaneously by the timestamps\n",
    "        separated_timestamps[pref], separated_file_lists[pref] = \\\n",
    "        (list(t) for t in zip(*sorted(zip(separated_timestamps[pref], separated_file_lists[pref]))))\n",
    "    \n",
    "    return separated_timestamps, separated_file_lists\n",
    "\n",
    "def get_sampling_period_from_file(infile):\n",
    "    #parse header for the timestep\n",
    "    f = open(infile, 'r', errors='ignore')\n",
    "    ls = f.readlines()\n",
    "    raw_sample_rate = ls[4]\n",
    "    raw_sample_rate = raw_sample_rate.split(' ')[-1]\n",
    "    raw_sample_rate = float(raw_sample_rate.split('H')[0])\n",
    "    return (1.0/raw_sample_rate)*1e9 #nanoseconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting random events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting utilities\n",
    "\n",
    "def plot_anode_scope(event_series, ax=None):\n",
    "    if(ax is None):\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    dt = event_series['SamplingPeriods'][0] #[0] and [1] are identical here, anode vs glitch\n",
    "    times = np.arange(0, len(event_series['Data'][0])*dt/1e6, dt/1e6)\n",
    "    ax.plot(times, event_series['Data'][0]*1000, label=\"Glitch\")\n",
    "    ax.plot(times, event_series['Data'][1]*1000, label=\"Anode\")\n",
    "    ax.set_xlabel(\"time (ms)\")\n",
    "    ax.set_ylabel(\"mV\")\n",
    "    ax.legend()\n",
    "    \n",
    "    return ax\n",
    "\n",
    "def plot_pmt_scope(event_series, ax=None):\n",
    "    if(ax is None):\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    dt = event_series['PMTSamplingPeriod'] #[0] and [1] are identical here, anode vs glitch\n",
    "    times = np.arange(0, len(event_series['Data'][0])*dt/1e3, dt/1e3)\n",
    "    ax.plot(times, event_series['Data'][0]*1000, label=\"PMT1\")\n",
    "    ax.plot(times, event_series['Data'][1]*1000, label=\"PMT2\")\n",
    "    ax.set_xlabel(\"time (us)\")\n",
    "    ax.set_ylabel(\"mV\")\n",
    "    ax.legend()\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n",
      "Picked 15 : 2-2-21/glitch-1320\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-77492884b257>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mseparated_file_lists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_separated_file_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatatopdir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_prefixes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Separation by prefix took \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \"\"\"\n",
      "\u001b[0;32m<ipython-input-4-dd0df7af9ab4>\u001b[0m in \u001b[0;36mget_separated_file_lists\u001b[0;34m(indir, file_prefixes)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_separated_file_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_prefixes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#full list of .csv files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     file_list = [f for f in os.listdir(indir) if \\\n\u001b[0m\u001b[1;32m     16\u001b[0m                  \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                  and f.endswith('.csv')]\n",
      "\u001b[0;32m<ipython-input-4-dd0df7af9ab4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#full list of .csv files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     file_list = [f for f in os.listdir(indir) if \\\n\u001b[0;32m---> 16\u001b[0;31m                  \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                  and f.endswith('.csv')]\n\u001b[1;32m     18\u001b[0m     \u001b[0mseparate_file_lists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_personal_env/lib/python3.7/genericpath.py\u001b[0m in \u001b[0;36misfile\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m\"\"\"Test whether a path is a regular file\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "#the part of the filename before the timestamp. \n",
    "#used to distinguish the two oscilloscopes\n",
    "file_prefixes = [\"pmt\", \"anode\"]\n",
    "\n",
    "#number of plots to show for every execution of this block\n",
    "n_random_plots = 10\n",
    "\n",
    "for i in range(n_random_plots):\n",
    "    print(\"Here\")\n",
    "    #pick a random number, a random dataset folder\n",
    "    key, dataset = random.choice(list(datasets.items()))\n",
    "    print(\"Picked \" + str(key) + \" : \" + dataset)\n",
    "    t0 = time.time()\n",
    "\n",
    "    separated_file_lists = get_separated_file_lists(datatopdir+dataset, file_prefixes)\n",
    "    print(\"Separation by prefix took \" + str(time.time() - t0))\n",
    "    \"\"\"\n",
    "    separated_timestamps, separated_file_lists = get_separated_timestamps(separated_file_lists)\n",
    "    \n",
    "    #print timing\n",
    "    print(\"Took \" + str(time.time() - t0) + \" seconds to load \", end=' ')\n",
    "    for pref in separated_timestamps:\n",
    "        print(str(len(separated_timestamps[pref])) + \" \" + pref + \" files,\", end=' ')\n",
    "    print(\"\\n\")\n",
    "    #end print timing\n",
    "    \n",
    "    #pick a random file from the list of PMT files\n",
    "    idx = np.random.randint(0, len(separated_file_lists['pmt'])) #is matched to timestamps too\n",
    "    infile = separated_file_lists['pmt'][idx]\n",
    "    event_series = pd.Series()\n",
    "    event_series['Timestamps'] = [parse_timestamp_from_filename(infile)]*2 #in milliseconds since 00:00 (midnight)\n",
    "    event_series['SamplingPeriods'] = [get_sampling_period_from_file(infile)]*2 #nanoseconds\n",
    "    #load the file\n",
    "    d = pd.read_csv(infile, header=None, skiprows=11, names=['ts','0','1'], encoding='iso-8859-1')\n",
    "    event_series['Channels'] = [\"pmt1\", \"pmt2\"]\n",
    "    event_series['ChannelTypes'] = [\"pmt\", \"pmt\"]\n",
    "    data_map = [d['0'].to_numpy(), d['1'].to_numpy()] \n",
    "    event_series['Data'] = data_map\n",
    "    \n",
    "    #find the anode file that is closest in time\n",
    "    pmt_time = separated_timestamps['pmt'][idx]\n",
    "    anode_idx = (np.abs(np.array(separated_timestamps['anode']) - pmt_time).argmin())\n",
    "    #load similar to the block above, but now appending to the event series\n",
    "    infile = separated_file_lists['anode'][anode_idx]\n",
    "    event_series['Timestamps'] += [parse_timestamp_from_filename(infile)]*2 #in milliseconds since 00:00 (midnight)\n",
    "    event_series['SamplingPeriods'] += [get_sampling_period_from_file(infile)]*2 #nanoseconds\n",
    "    #load the file\n",
    "    d = pd.read_csv(infile, header=None, skiprows=11, names=['ts','0','1'], encoding='iso-8859-1')\n",
    "    event_series['Channels'] += [\"glitch\", \"anode\"]\n",
    "    event_series['ChannelTypes'] = [\"glitch\", \"anode\"]\n",
    "    data_map = [d['0'].to_numpy(), d['1'].to_numpy()] \n",
    "    event_series['Data'] += data_map\n",
    "    \n",
    "    print(event_series['Data'])\n",
    "    print(event_series['SamplingPeriods'])\n",
    "    exit()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
