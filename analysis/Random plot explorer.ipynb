{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "%matplotlib inline\n",
    "import mpld3\n",
    "mpld3.enable_notebook()\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.style.use('~/evanstyle.mplstyle')\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary of datasets on LLNL. Checks if they exist and how many files\n",
    "### Note, the integer index of this dictionary matches the row number in the google-spreadsheet log\n",
    "##### https://docs.google.com/spreadsheets/d/14KmVPS824ExjVpss9H6fMSNVhopGtHVclZNsw5kKLr8/edit?usp=sharing\n",
    "##### Save this sheet to your own drive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for datasets in top directory: /p/lustre1/angelico/hv-test-chamber/\n",
      "2: 1-29-21/pmt-trig-filling-1800\t\tTrue, with 3019 files\n",
      "3: 1-29-21/pmt-trig-filling-1920\t\tTrue, with 81718 files\n",
      "4: 1-30-21/anode-crosstrig-1300\t\tTrue, with 161 files\n",
      "5: 1-30-21/anode-crosstrig-1320\t\tFalse\n",
      "6: 1-30-21/ignition-1500\t\tTrue, with 3795 files\n",
      "7: 1-30-21/ignition-10k-1520\t\tTrue, with 10849 files\n",
      "8: 1-31-21/glitch-1520\t\tTrue, with 10398 files\n",
      "9: 2-1-21/anode-100\t\tTrue, with 15628 files\n",
      "10: 2-1-21/anode-1340\t\tTrue, with 208 files\n",
      "11: 2-1-21/glitch-1530\t\tTrue, with 5333 files\n",
      "12: 2-1-21/glitch-2230\t\tTrue, with 8129 files\n",
      "13: 2-2-21/anode-1030\t\tTrue, with 22247 files\n",
      "14: 2-2-21/corona-1300\t\tTrue, with 2817 files\n",
      "15: 2-2-21/glitch-1320\t\tTrue, with 14598 files\n",
      "16: 2-2-21/glitch-1430\t\tFalse\n",
      "17: 2-2-21/anode-1720\t\tTrue, with 21034 files\n",
      "18: 2-3-21/glitch-1040\t\tFalse\n",
      "19: 2-3-21/anode-1050\t\tTrue, with 59444 files\n",
      "20: 2-3-21/glitch-1810\t\tFalse\n",
      "21: 2-3-21/anode-1820\t\tTrue, with 156841 files\n"
     ]
    }
   ],
   "source": [
    "datatopdir = \"/p/lustre1/angelico/hv-test-chamber/\"\n",
    "datasets = {2:\"1-29-21/pmt-trig-filling-1800\", \\\n",
    "                3:\"1-29-21/pmt-trig-filling-1920\",\\\n",
    "                4:\"1-30-21/anode-crosstrig-1300\",\\\n",
    "                5:\"1-30-21/anode-crosstrig-1320\",\\\n",
    "                6:\"1-30-21/ignition-1500\",\\\n",
    "                7:\"1-30-21/ignition-10k-1520\",\\\n",
    "                8:\"1-31-21/glitch-1520\",\\\n",
    "                9:\"2-1-21/anode-100\",\\\n",
    "                10:\"2-1-21/anode-1340\",\\\n",
    "                11:\"2-1-21/glitch-1530\",\\\n",
    "                12:\"2-1-21/glitch-2230\",\\\n",
    "                13:\"2-2-21/anode-1030\",\\\n",
    "                14:\"2-2-21/corona-1300\",\\\n",
    "                15:\"2-2-21/glitch-1320\",\\\n",
    "                16:\"2-2-21/glitch-1430\",\\\n",
    "                17:\"2-2-21/anode-1720\",\\\n",
    "                18:\"2-3-21/glitch-1040\",\\\n",
    "                19:\"2-3-21/anode-1050\",\\\n",
    "                20:\"2-3-21/glitch-1810\",\\\n",
    "                21:\"2-3-21/anode-1820\"}\n",
    "\n",
    "#check that the datasets are indexible\n",
    "print(\"Checking for datasets in top directory: \" + datatopdir)\n",
    "to_remove = [] #list of keys to remove due to not existing\n",
    "for dno in datasets:\n",
    "    print(str(dno)+\": \" + datasets[dno] + \"\\t\\t\", end = '')\n",
    "    isdir = os.path.isdir(datatopdir+datasets[dno]+\"/\")\n",
    "    if(isdir):\n",
    "        numfiles = len([_ for _ in os.listdir(datatopdir+datasets[dno]+\"/\")])\n",
    "        print(\"True, with \" + str(numfiles) + \" files\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "        to_remove.append(dno)\n",
    "        \n",
    "\n",
    "for k in to_remove:\n",
    "    del datasets[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions for parsing file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_timestamp_from_filename(infile):\n",
    "    #infile looks like /path/to/data/file/pmt15.23.43.132.csv (hour, minute, second, milli)\n",
    "    t = infile.split('/')[-1].split('.')[:-1]\n",
    "    t[0] = t[0][-2:] #hour is always only two digits, this line just ignores file prefix \n",
    "    t = [int(_) for _ in t]\n",
    "    #now is in form [hours, minutes, seconds, millis]\n",
    "    milliseconds = t[3] + 1e3*t[2] + 1e3*60*t[1] + 1e3*60*60*t[0]\n",
    "    return milliseconds\n",
    "\n",
    "#looks at the input directory (a dataset) and\n",
    "#finds all .csv files, separating them by file prefix\n",
    "def get_separated_file_lists(indir, file_prefixes):\n",
    "    #full list of .csv files\n",
    "    file_list = [f for f in os.listdir(indir) if \\\n",
    "                 os.path.isfile(os.path.join(indir, f)) \\\n",
    "                 and f.endswith('.csv')]\n",
    "    separate_file_lists = {}\n",
    "    for pref in file_prefixes:\n",
    "        #selects filenames by prefix. so separate_file_lists['pmt'] = ['pmt14.53.24.449', 'pmt10.34....', ...]\n",
    "        separate_file_lists[pref] = list(filter(lambda x: x[:len(pref)] == pref, file_list))  \n",
    "        #add the indir to the beginning of each filename so that\n",
    "        #any file readers know what's up. \n",
    "        separate_file_lists[pref] = [indir+_ for _ in separate_file_lists[pref]]\n",
    "    \n",
    "    return separate_file_lists\n",
    "\n",
    "#converts the dictionary of separated file lists into\n",
    "#a dictionary of separated timestamps (units milliseconds)\n",
    "def get_separated_timestamps(separated_file_lists):\n",
    "    separated_timestamps = {}\n",
    "    for pref in separated_file_lists:\n",
    "        separated_timestamps[pref] = [parse_timestamp_from_filename(f) for f\\\n",
    "                                      in separated_file_lists[pref]]\n",
    "       \n",
    "        #sort both the timestamps lists and the filelists\n",
    "        #simultaneously by the timestamps\n",
    "        separated_timestamps[pref], separated_file_lists[pref] = \\\n",
    "        (list(t) for t in zip(*sorted(zip(separated_timestamps[pref], separated_file_lists[pref]))))\n",
    "    \n",
    "    return separated_timestamps, separated_file_lists\n",
    "\n",
    "def get_sampling_period_from_file(infile):\n",
    "    #parse header for the timestep\n",
    "    f = open(infile, 'r', errors='ignore')\n",
    "    ls = f.readlines()\n",
    "    raw_sample_rate = ls[4]\n",
    "    raw_sample_rate = raw_sample_rate.split(' ')[-1]\n",
    "    raw_sample_rate = float(raw_sample_rate.split('H')[0])\n",
    "    return (1.0/raw_sample_rate)*1e9 #nanoseconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting random events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "#plotting sub-function\n",
    "def plot_event(event_series):\n",
    "    fig, ax = plt.subplots(nrows = 2, figsize=(10, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n",
      "Picked 15 : 2-2-21/glitch-1320\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-77492884b257>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mseparated_file_lists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_separated_file_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatatopdir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_prefixes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Separation by prefix took \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \"\"\"\n",
      "\u001b[0;32m<ipython-input-4-dd0df7af9ab4>\u001b[0m in \u001b[0;36mget_separated_file_lists\u001b[0;34m(indir, file_prefixes)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_separated_file_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_prefixes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#full list of .csv files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     file_list = [f for f in os.listdir(indir) if \\\n\u001b[0m\u001b[1;32m     16\u001b[0m                  \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                  and f.endswith('.csv')]\n",
      "\u001b[0;32m<ipython-input-4-dd0df7af9ab4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#full list of .csv files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     file_list = [f for f in os.listdir(indir) if \\\n\u001b[0;32m---> 16\u001b[0;31m                  \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                  and f.endswith('.csv')]\n\u001b[1;32m     18\u001b[0m     \u001b[0mseparate_file_lists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_personal_env/lib/python3.7/genericpath.py\u001b[0m in \u001b[0;36misfile\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m\"\"\"Test whether a path is a regular file\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "#the part of the filename before the timestamp. \n",
    "#used to distinguish the two oscilloscopes\n",
    "file_prefixes = [\"pmt\", \"anode\"]\n",
    "\n",
    "#number of plots to show for every execution of this block\n",
    "n_random_plots = 10\n",
    "\n",
    "for i in range(n_random_plots):\n",
    "    print(\"Here\")\n",
    "    #pick a random number, a random dataset folder\n",
    "    key, dataset = random.choice(list(datasets.items()))\n",
    "    print(\"Picked \" + str(key) + \" : \" + dataset)\n",
    "    t0 = time.time()\n",
    "\n",
    "    separated_file_lists = get_separated_file_lists(datatopdir+dataset, file_prefixes)\n",
    "    print(\"Separation by prefix took \" + str(time.time() - t0))\n",
    "    \"\"\"\n",
    "    separated_timestamps, separated_file_lists = get_separated_timestamps(separated_file_lists)\n",
    "    \n",
    "    #print timing\n",
    "    print(\"Took \" + str(time.time() - t0) + \" seconds to load \", end=' ')\n",
    "    for pref in separated_timestamps:\n",
    "        print(str(len(separated_timestamps[pref])) + \" \" + pref + \" files,\", end=' ')\n",
    "    print(\"\\n\")\n",
    "    #end print timing\n",
    "    \n",
    "    #pick a random file from the list of PMT files\n",
    "    idx = np.random.randint(0, len(separated_file_lists['pmt'])) #is matched to timestamps too\n",
    "    infile = separated_file_lists['pmt'][idx]\n",
    "    event_series = pd.Series()\n",
    "    event_series['Timestamps'] = [parse_timestamp_from_filename(infile)]*2 #in milliseconds since 00:00 (midnight)\n",
    "    event_series['SamplingPeriods'] = [get_sampling_period_from_file(infile)]*2 #nanoseconds\n",
    "    #load the file\n",
    "    d = pd.read_csv(infile, header=None, skiprows=11, names=['ts','0','1'], encoding='iso-8859-1')\n",
    "    event_series['Channels'] = [\"pmt1\", \"pmt2\"]\n",
    "    event_series['ChannelTypes'] = [\"pmt\", \"pmt\"]\n",
    "    data_map = [d['0'].to_numpy(), d['1'].to_numpy()] \n",
    "    event_series['Data'] = data_map\n",
    "    \n",
    "    #find the anode file that is closest in time\n",
    "    pmt_time = separated_timestamps['pmt'][idx]\n",
    "    anode_idx = (np.abs(np.array(separated_timestamps['anode']) - pmt_time).argmin())\n",
    "    #load similar to the block above, but now appending to the event series\n",
    "    infile = separated_file_lists['anode'][anode_idx]\n",
    "    event_series['Timestamps'] += [parse_timestamp_from_filename(infile)]*2 #in milliseconds since 00:00 (midnight)\n",
    "    event_series['SamplingPeriods'] += [get_sampling_period_from_file(infile)]*2 #nanoseconds\n",
    "    #load the file\n",
    "    d = pd.read_csv(infile, header=None, skiprows=11, names=['ts','0','1'], encoding='iso-8859-1')\n",
    "    event_series['Channels'] += [\"glitch\", \"anode\"]\n",
    "    event_series['ChannelTypes'] = [\"glitch\", \"anode\"]\n",
    "    data_map = [d['0'].to_numpy(), d['1'].to_numpy()] \n",
    "    event_series['Data'] += data_map\n",
    "    \n",
    "    print(event_series['Data'])\n",
    "    print(event_series['SamplingPeriods'])\n",
    "    exit()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Angelico home kernel",
   "language": "python",
   "name": "angelico-home-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
